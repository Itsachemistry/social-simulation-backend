

### **你的核心任务：构建仿真引擎 (The Simulation Engine)**

你的使命是创建一个稳定、可扩展的后端服务。这个服务能够接收一个初始的“世界”配置（包含帖子数据和角色设定），然后驱动这个“世界”按照预设的规则演化，并记录下整个演化过程中的所有关键数据，最终将这些数据提供给前端进行可视化。

---

### **模块一：时间与流程管理器 (The Time & Flow Manager)**

这是你的“导演椅”和“场记板”，负责控制整个仿真的宏观节奏。

* **1.1 实现时间片机制 (Time Slice Mechanism)**
    * **职责**: 你需要设计一个机制来管理“时间”。
    * **具体工作**:
        * [cite_start]读取初始的帖子数据，根据时间戳对所有帖子进行排序 [cite: 158]。
        * [cite_start]根据设定的规模（比如每50个帖子），将这些有序的帖子划分成一个个独立的“时间片 (Time Slice)” [cite: 159]。
        * 你要维护一个指向“当前时间片”的指针，驱动仿真从一个时间片前进到下一个。

* **1.2 搭建主仿真循环 (Main Simulation Loop)**
    * **职责**: 这是你后端程序的核心骨架，一个循环体，每循环一次，就处理一个时间片。
    * **具体工作**:
        * 在每个时间片的开始，你需要准备好当前时间片内的所有环境信息。
        * 在循环体内，你会调用**模块三（Agent控制器）**来依次处理每个Agent的行动。
        * 在时间片结束时，你需要收集本轮生成的新帖子，并将它们放入一个临时的“待发布区”，准备在下一个时间片中加入主帖子池。

---

### **模块二：世界状态管理器 (The World State Manager)**

这是你的“摄影棚”和“道具库”，负责管理仿真世界中所有非Agent的公共资源。

* **2.1 维护动态帖子池 (Dynamic Post Pool)**
    * **职责**: 管理整个舆论场中所有可见的帖子。
    * **具体工作**:
        * 你需要一个核心的数据结构（比如一个列表或数据库表）来存储所有的帖子对象。
        * [cite_start]这个池子是动态的：它初始时包含了真实世界的数据，在仿真过程中，由Agent生成的新帖子会不断被添加进来 [cite: 161, 186]。
        * 你需要为每篇帖子维护一些动态属性，比如“热度”，这个值可能会随着被浏览、被转发而变化。

* **2.2 实现全局事件注入器 (Global Event Injector)**
    * [cite_start]**职责**: 根据论文描述，系统需要支持引入“突发公共事件” [cite: 106]。
    * **具体工作**:
        * 你需要设计一个机制，允许在特定的时间点（或时间片）向帖子池中强制插入一条高权重的“突发新闻”帖子。
        * [cite_start]这条新闻需要被标记，以确保所有Agent都能接收到它，从而模拟重大新闻对舆论的冲击效应 [cite: 106, 197]。

---

### **模块三：Agent控制器 (The Agent Controller)**

这是你的“演员调度中心”，是你与你队友（Agent设计师）工作结合最紧密的地方。

* **3.1 Agent的初始化与生命周期管理**
    * **职责**: 在仿真开始时，加载所有Agent的配置，并创建它们的实例（对象）。
    * **具体工作**:
        * 读取预设的Agent配置文件（可能是一个JSON或YAML文件）。
        * 根据配置文件，使用你队友提供的`Agent`类，批量创建出所有参与仿真的Agent对象，并存储起来（比如放在一个列表或字典里）。
        * 你要为每个Agent分配唯一的ID。

* **3.2 实现行动顺序调度器 (Turn-based Scheduler)**
    * [cite_start]**职责**: 在每个时间片内，严格按照论文描述的顺序来安排Agent的行动 [cite: 160-163]。
    * **具体工作**:
        * 你首先要识别出哪些是“意见领袖”，让他们先行动。
        * 然后是“基于规则的Agent”。
        * 最后是大量的“普通用户Agent”。
        * 你的代码需要遍历Agent列表，并根据他们的类型来决定谁先谁后。

* **3.3 实现个性化信息流生成器 (Personalized Feed Generator)**
    * **职责**: 这是你后端最复杂也最核心的逻辑之一。你必须为每个Agent模拟出它在社交媒体上“刷到的信息流”。
    * **具体工作**:
        * 当轮到某个Agent行动时，你不能把“世界状态管理器”里的所有帖子都给它。
        * [cite_start]你需要从帖子池中，根据帖子的**热度**和**发帖人与当前Agent的立场相似度**进行加权筛选，为该Agent生成一个数量有限的、个性化的“待浏览列表” [cite: 154, 157, 165]。
        * [cite_start]同时，你需要检查这个Agent的“黑名单”，确保被拉黑的用户的帖子不会出现在这个列表里 [cite: 167]。

* **3.4 执行Agent的核心交互逻辑 (Action Execution)**
    * **职责**: 编排与单个Agent对象的完整交互过程。
    * **具体工作**:
        1.  **信息输入**: 遍历你为Agent生成的“个性化信息流”，将每篇帖子的数据作为参数，调用Agent对象的 `update_state(帖子数据)` 方法。
        2.  **触发行动**: 在Agent“看完”所有信息后，根据规则判断它是否要发言。
        3.  **获取Prompt**: 如果它决定发言，调用它的 `generate_action_prompt()` 方法，拿到它准备好的、发给LLM的Prompt文本。
        4.  **调用外部服务**: 将这个Prompt文本传递给**模块四（服务层）**中的LLM连接器。
        5.  **处理结果**: 从LLM连接器那里拿到生成的新帖子内容，然后把它交给**模块二（世界状态管理器）**添加到公共帖子池中。

---

### **模块四：通用服务层 (The Services Layer)**

这是你的“后勤部门”，负责处理所有与外部世界的连接和数据存取。

* **4.1 实现数据加载器 (Data Loader)**
    * **职责**: 负责在仿真开始时读取所有需要的文件。
    * **具体工作**:
        * [cite_start]读取并解析包含真实世界帖子数据的JSON文件 [cite: 89]。
        * 读取并解析Agent的配置文件。

* **4.2 实现LLM服务连接器 (LLM Service Connector)**
    * **职责**: 专门负责和LLM API打交道。
    * **具体工作**:
        * 创建一个独立的模块或类，它的功能很简单：接收一个Prompt文本，向LLM的API地址发送请求，然后返回LLM生成的文本。
        * 这样做的好处是**解耦**：如果未来需要更换LLM模型，你只需要修改这一个模块，而你的核心仿真逻辑（模块一、二、三）完全不受影响。

* **4.3 实现结果记录器 (Results Logger)**
    * **职责**: 将仿真过程中产生的所有重要数据实时或定期地记录下来。
    * **具体工作**:
        * [cite_start]在每个Agent的状态更新后，记录下它的新状态（情绪、立场、置信度）以及是哪篇帖子导致了这次更新 [cite: 184-185]。
        * [cite_start]记录下Agent生成的每一篇新帖子 [cite: 186]。
        * 将所有这些日志数据以结构化的格式（如JSON Lines或写入数据库）保存下来，以便前端可以读取这些数据来进行可视化展示。

---
### **总结：你的工作蓝图**
你的工作是搭建一个强大的、模块化的仿真平台。你需要管理时间的流动，维护世界的状态，调度每一个角色的行动，并连接外部的服务。你为所有Agent提供了一个表演的舞台，并确保它们的每一次表演都被精确地记录下来。这个平台的好坏，直接决定了整个研究能否顺利进行和复现。